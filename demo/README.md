# Overview

This repository contains the elPrep demo files:

Demo 1:

* [run-large.sh]: a bash script that runs a 3-step preparation pipeline using elPrep on "NA12878-chr22", a subset of [whole-genome sequencing of  NA12878](http://www.ebi.ac.uk/ena/data/view/ERS189474) that maps to chromosome 22
* [run-small.sh]: a bash script that runs a 3-step pipeline using elPrep on 10% of the reads of NA12878-chr22 

Demo 2:

* [run-large-gatk.sh]: a bash script that runs a 5-step preparation pipeline on NA12878-chr22 to transform it into something that can be used as input for GATK
* [run-small-gatk.sh]: a bash script that runs the  same 5-step preparation pipeline using elPrep on 10% of the reads of NA12878-chr22

Demo 3:

* [run-wes-gatk.sh]: a bash script that runs the 5-step preparation pipeline using elPrep split/filter/merge on "SRR1611184", a high-coverage [whole-exome sequencing of NA12878](http://www.ncbi.nlm.nih.gov/sra/SRX731649[accn])

Other files and scripts:

* [clean.sh]: a bash script for deleting the output files generated by executing the pipeline scripts
* [ucsc.hg19.dict]: a .sam/.bam header file compatible with GATK

Upon executing one of the run scripts for the first time, the following input .bam files are downloaded:

* [NA12878-chr22.bam]: a subset of [whole-genome sequencing of NA12878](http://www.ebi.ac.uk/ena/data/view/ERS189474) that maps to chromosome 22, created using BWA (1.2GB).
* [NA12878-chr22-10pct.bam]: the first 10% entries of NA12878-chr22.bam (120MB).
* [SRR1611184.bam]: a [whole-exome sequencing of NA12878](http://www.ncbi.nlm.nih.gov/sra/SRX731649[accn]) mapped using BWA (13GB). This is a complete, real-world workload.


Alternatively, you can also download these files manually [here](http://www.exascience.com/public-files/elprep-demo/).

# System requirements

## Operating system

elPrep is developed for Linux and has been tested with the following distributions:

* Ubuntu 14.04.5 LTS
* Ubuntu 12.04.3 LTS
* Manjaro Linux
* Red Hat Enterprise Linux 6.4 and 6.5

## Workloads

We recommend using NA12878-chr22-10pct.bam for quick testing and checking that the installation of elPrep is correct. NA12878-chr22.bam can be used for performance checks when running elPrep on a server. Finally, SRR1611184.bam is a complete, real-world workload.

### NA12878-chr22-10pct.bam (120MB)

The minimal system requirements are:

	* For demo 1:

		* RAM: 			867	MB
		* Disk space: 	  241.0	MB

	* For demo 2:

		* RAM:			   3.1	GB
		* DisK space:	 241.0	MB

On our test machine, a server with two 18-core Intel Xeon Haswell processors clocked at 2.3 Ghz running Ubuntu 14.04.5 LTS, the observed runtimes for elPrep 2.61 are:

	* For demo 1: 
		* with 72 threads:	   5s 
		
	* For demo 2:
		* with 72 threads:	   5s 

### NA12878-chr22.bam (1.2GB)

The minimal system requirements are:

	* For demo 1:

		* RAM: 			2	GB
		* Disk space: 	 2.4	GB

	* For demo 2:

		* RAM:			30.51	GB
		* Disk space:	 2.4	GB

On our test machine, a server with two 18-core Intel Xeon Haswell processors clocked at 2.3 Ghz running Ubuntu 14.04.5 LTS, the observed runtimes for elPrep 2.61 are:

	* For demo 1: 
		* with 72 threads:	45s 
	
	* For demo 2: 
		* with 72 threads:	47s 


### SRR1611184.bam (13GB)

The minimal system requirements are:

	* For demo 3:
	
		* RAM:				21.57	GB
		* Disk space:		26	GB

On our test machine, a server with two 18-core Intel Xeon Haswell processors clocked at 2.3 Ghz running Ubuntu 14.04.5 LTS, the observed runtime for elPrep 2.61 is:

	For demo 3:
		* with 72 threads:	16m 12s
		

# Running the demos

## Path setup

Install SAMtools and elPrep and add them to your path. For example, fill in your username and execute:

	export PATH=$PATH:/home/username/tools/samtools-1.5:/home/username/tools/elprep-v2.61:

## Demo 1: a simple preparation pipeline

The scripts run-large.sh and run-small.sh execute a prepartion pipeline that consists of removing the unmapped reads, replacing the reference dictionary, and adding read groups, respectively for the large (NA12878-chr22) and small (NA12878-chr22-10pct) input files. 

1) By default, the scripts use the maximum number of available threads, based on your processor's capabilities. If you want to use a different number of threads, edit the scripts to do so (cf. 2nd line).

2) Run the scripts by executing:

	sh run-small.sh 	

for the small .bam file

or

	sh run-large.sh

for the large .bam file.

Executing these scripts will print the following feedback for the small .bam file:

elPrep version 2.61. See http://github.com/exascience/elprep for more information.

Executing command:

  elprep NA12878-chr22-10pct.bam NA12878-chr22-10pct.only_mapped.reordered-contigs.read-group.bam --filter-unmapped-reads --replace-reference-sequences ucsc.hg19.dict --replace-read-group "ID:group1 LB:lib1 PL:illumina PU:unit1 SM:sample1" --sorting-order unknown --gc-on 2 --nr-of-threads 72

or the following feedback for the large .bam file:

elPrep version 2.61. See http://github.com/exascience/elprep for more information.

Executing command:

  elprep NA12878-chr22.bam NA12878-chr22.only_mapped.reordered-contigs.read-group.bam --filter-unmapped-reads --replace-reference-sequences ucsc.hg19.dict --replace-read-group "ID:group1 LB:lib1 PL:illumina PU:unit1 SM:sample1" --sorting-order unsorted --gc-on 2 --nr-of-threads 72

The elPrep commands that are printed in the feedback are the actual elPrep commands that are executed by those scripts. Hence you can also copy-paste these commands directly into your terminal instead of running the bash scripts.

## Demo 2: a preparation pipeline for making the data processable by GATK

The scripts run-large-gatk.sh and run-small-gatk.sh execute a 5-step preparation pipeline that consists of removing the unmapped reads, replacing the reference sequence dictionary, adding read groups, marking duplicates, and sorting by coordinate order. 

1) By default, the scripts use the maximum number of available threads, based on your processor's capabilities. If you want to use a different number of threads, edit the scripts to do so (cf. 2nd line).

2) Run the scripts by executing:

	sh run-small-gatk.sh 	

for the small .bam file

or

	sh run-large-gatk.sh

Executing these scripts will print the following feedback for the small .bam file:

elPrep version 2.61. See http://github.com/exascience/elprep for more information.

Executing command:

  elprep NA12878-chr22-10pct.bam NA12878-chr22-10pct.only_mapped.reordered-contigs.sorted.deduplicated.read-group.bam --filter-unmapped-reads --replace-reference-sequences ucsc.hg19.dict --replace-read-group "ID:group1 LB:lib1 PL:illumina PU:unit1 SM:sample1" --mark-duplicates --sorting-order coordinate --gc-on 0 --nr-of-threads 72 --split-file
	  
or the following for the large .bam file:

elPrep version 2.61. See http://github.com/exascience/elprep for more information.

Executing command:

  elprep NA12878-chr22.bam NA12878-chr22.only_mapped.reordered-contigs.sorted.deduplicated.read-group.bam --filter-unmapped-reads --replace-reference-sequences ucsc.hg19.dict --replace-read-group "ID:group1 LB:lib1 PL:illumina PU:unit1 SM:sample1" --mark-duplicates --sorting-order coordinate --gc-on 0 --nr-of-threads 72 --split-file

The elPrep commands that are printed in the feedback are the actual elPrep commands that are executed by those scripts. Hence you can also copy-paste these commands directly into your terminal instead of running the bash scripts.

## Demo 3: a preparation pipeline using elprep split/filter/merge

The script run-wes-gatk.sh executes a 5-step pipeline that consists of removing the unmapped reads, replacing the reference seuqence dictionary, adding read groups, marking duplicates, and sorting by coordinate order. The script executes this pipeline using the elprep split/filter/merge approach. This script is only executable for the whole-exome data set (SRR1611184.bam).

1) By default, the scripts use the maximum number of available threads, based on your processor's capabilities. If you want to use a different number of threads, edit the scripts to do so (cf. 2nd line).

2) Run the script by executing:

	sh run-wes-gatk.sh

Executing this script will print the following feedback:

First, a call to the elprep split command is shown:

elPrep version 2.61. See http://github.com/exascience/elprep for more information.

Executing command:

  elprep split /dev/stdin /scratch/username/elprep-old-demo/temp-1506520452.55/ --output-prefix SRR1611184 --output-type sam --nr-of-threads 72
elPrep version 2.61. See http://github.com/exascience/elprep for more information.

Afterwards, a series of regular elprep commands is performed, one for each split file:

elPrep version 2.61. See http://github.com/exascience/elprep for more information.

Executing command:

  elprep /scratch/username/elprep-old-demo/temp-1506520452.55/splits/SRR1611184-chr6_cox_hap2.sam /scratch/username/elprep-old-demo/temp-processed-1506520452.55/SRR1611184-chr6_cox_hap2.sam --filter-unmapped-reads --replace-reference-sequences ucsc.hg19.dict --replace-read-group "ID:group1 LB:lib1 PL:illumina PU:unit1 SM:sample1" --mark-duplicates --sorting-order coordinate --gc-on 0 --nr-of-threads 72 --split-file

	...
  
Finally, an elprep merge command is performed to combine the results of the split files into a single output file:

elPrep version 2.61. See http://github.com/exascience/elprep for more information.

Executing command:

  elprep merge /scratch/username/elprep-old-demo/temp-processed-1506520452.55/ /dev/stdout --nr-of-threads 72
	  
## Resetting the demos

To remove the output files generated by executing the demos, execute the clean script:

	sh clean.sh
